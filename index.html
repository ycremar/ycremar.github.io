<!DOCTYPE HTML>

<html>

<head>
	<!-- Google tag (gtag.js) -->
	<script async src="https://www.googletagmanager.com/gtag/js?id=G-5SM0ZS98SH"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'G-5SM0ZS98SH');
	</script>

	<title>Yaochen (Ethan) Xie</title>
	<meta charset="utf-8" />
	<meta name="google-site-verification" content="YoSFv-xUytsvz-aYqBNagl5sX8WKte4whKdDIoA2PjU" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
	<link rel="stylesheet" href="assets/css/timeline.css">
	<link rel="stylesheet" href="assets/css/main.css" />
	<link rel="stylesheet" href="assets/css/font-awesome.min.css">
</head>

<body id="top">

	<!-- Header -->
	<header id="header">
		<div class="inner">
			<a href="#" class="image avatar"><img src="images/avatar.png" alt="" /></a>
			<h1>
				<strong style="background-color: rgba(64,0,64,.6)">Yaochen (Ethan) Xie</strong><br /> 
			</h1>
			<h1><i style="background-color: rgba(64,0,64,.6)">
				Applied Scientist II<br />
				Amazon Search<br />
			</i></h1>
		</div>
		<div class="bg-image">
	        <img id="noisy-img" src="images/noisy.png" alt="noisy image" />
	        <img id="denoised-img" src="images/denoised.png" alt="denoised image" />
	    </div>
	</header>

	<!-- Main -->
	<div id="main">

		<!-- Biography -->
		<section id="bio">
			<header style="margin-bottom: 10px;" class="major">
				<h2>Howdy!</h2>
			</header>
			<p>I'm an Applied Scientist at Amazon Search. I received my Ph.D. in Computer Science from Texas A&amp;M University advised by <a href="https://people.tamu.edu/~sji/">Prof. Shuiwang Ji</a>. Prior to that, I obtained my B.S. in Statistics from the <a href="https://en.wikipedia.org/wiki/Special_Class_for_the_Gifted_Young">School of the Gifted Young</a> at University of Science and Technology of China. My research work aims to improve the applicability and reliability of machine learning and deep learning approaches to drive broader industrial applications and scientific discovery (AI4Science). I currently serve as an Area Chair at Language and Molecule @ ACL and in the program committees of NeurIPS, ICML, and ICLR.
			<br> <br> 
			<p><a href="https://scholar.google.com/citations?user=Xw3ZjnMAAAAJ" class="fa fa-graduation-cap" target="_blank"> Google Scholar</a>&ensp;&ensp;<a href="https://www.linkedin.com/in/yaochen-xie-44602994/" class="fa fa-linkedin" target="_blank"> LinkedIn</a>&ensp;&ensp;<a href="https://github.com/ycremar" class="fa fa-github"> Github</a>
			<!-- &ensp;&ensp;<a href="Curriculum_vitae.pdf" class="fa fa-file-text-o" target="_blank"> Curriculum Vitae</a> -->
			</p>
			<!-- <p><i>Our team is hiring multiple Applied Scientist Interns for 2024 Summer. Candidates experienced in ML/NLP/DM with strong publication record are preferred. Please reach out if you are interested.</i></p> -->
		</section>

		<!-- Education -->
		<section id="edu">
			<h2 style="margin-bottom: 10px;">Research Interests</h2>
			<section>
				<li>Large Language Models, Retrieval Augemented Generation, Multi-Modality</li>
				<li>Self-Supervised Learning and Foundation Models</li>
				<li>Model Explanability</li>
				<li>Graph Neural Networks</li>
				<li>AI4Science: Geometric Deep Learning, Bioinfomatics, Biomedical Imaging</li>
			</section>
		</section >

		<!-- Publication -->
		<section id="Pub">
			<h2>Selected Publications</h2>

			* Equally contributed.
			<section>

			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://openreview.net/forum?id=LSYhE2hLWG" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/AIRS" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>SineNet: Learning Temporal Dynamics in Time-Dependent Partial Differential Equations.</b></p>
			  <p style="margin-top: 3px;">Xuan Zhang, Jacob Helwig, Yuchao Lin, <strong>Yaochen Xie</strong>, Cong Fu, Stephan Wojtowytsch, Shuiwang Ji</p>
			  <p><i>International Conference on Learning Representations (<strong>ICLR</strong>), 2024</i>
			  </p>
			</div>
			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://arxiv.org/abs/2309.15132" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<b>Genetic InfoMax: Exploring Mutual Information Maximization in High-Dimensional Imaging Genetics Studies.</b></p>
			  <p style="margin-top: 3px;"><strong>Yaochen Xie</strong>, Ziqian Xie, Sheikh Muhammad Saiful Islam, Degui Zhi, Shuiwang Ji</p>
			  <p><i>Preprint, 2023</i>
			  </p>
			</div>

			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://arxiv.org/abs/2307.08423" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/AIRS" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>Artificial Intelligence for Science in Quantum, Atomistic, and Continuum Systems.</b></p>
			  <p style="margin-top: 3px;">Xuan Zhang*, Limei Wang*, Jacob Helwig*, Youzhi Luo*, Cong Fu*, <strong>Yaochen Xie</strong>*, ... (47 more), Jure Leskovec, Heng Ji, Jimeng Sun, Regina Barzilay, Tommi Jaakkola, Connor W Coley, Xiaoning Qian, Xiaofeng Qian, Tess Smidt, Shuiwang Ji</p>
			  <p><i>Preprint, 2023</i>
			  </p>
			</div>

			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://arxiv.org/abs/2202.08335" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/DIG/tree/main/dig/xgraph/TAGE" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>Task-Agnostic Graph Explanations.</b></p>
			  <p style="margin-top: 3px;"><strong>Yaochen Xie</strong>, Sumeet Katariya, Xianfeng Tang, Edward Huang, Nikhil Rao, Karthik Subbian, Shuiwang Ji</p>
			  <p><i>The 36th Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022</i>
			  </p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://proceedings.mlr.press/v162/xie22e.html" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/DIG/tree/dig/examples/sslgraph/LaGraph" class="fa fa-github"></a>&ensp;
			  	<b>Self-Supervised Representation Learning via Latent Graph Prediction.</b></p>
			  <p style="margin-top: 3px;"><strong>Yaochen Xie</strong>*, Zhao Xu*, and Shuiwang Ji</p>
			  <p><i>International Conference on Machine Learning (<strong>ICML</strong>), 24460-24477, 2022.</i>
			  </p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://arxiv.org/abs/2107.09787" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<b>Group Contrastive Self-Supervised Learning on Graphs.</b>
			  </p>
			  <p style="margin-top: 3px;">Xinyi Xu, Cheng Deng, <strong>Yaochen Xie</strong>, Shuiwang Ji</p>
			  <p><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2022.
			  </i></p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://ieeexplore.ieee.org/document/9764632" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<b>Self-supervised Learning of Graph Neural Networks: A Unified Review.</b>
			  </p>
			  <p style="margin-top: 3px;"><strong>Yaochen Xie</strong>, Zhao Xu, Jingtun Zhang, Zhengyang Wang, and Shuiwang Ji</p>
			  <p><i>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>), 2022.
			  </i></p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://ieeexplore.ieee.org/document/9785968/" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/AEANets" class="fa fa-github"></a>&ensp;
			  	<b>Augmented Equivariant Attention Networks for Microscopy Image Transformation.</b>
			  </p>
			  <p style="margin-top: 3px;"><strong>Yaochen Xie</strong>, Yu Ding, Shuiwang Ji</p>
			  <p><i>IEEE Transactions on Medical Imaging (<strong>TMI</strong>), 2022.
			  </i></p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://academic.oup.com/bioinformatics/article/38/9/2579/6531963" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/MoleculeX" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>Advanced graph and sequence neural networks for molecular property prediction <br> and drug discovery.</b>
			  </p>
			  <p style="margin-top: 3px;">Zhengyang Wang*, Meng Liu*, Youzhi Luo*, Zhao Xu*, <strong>Yaochen Xie*</strong>, Limei Wang*, Lei Cai*, Qi Qi, Zhuoning Yuan, Tianbao Yang, Shuiwang Ji.</p>
			  <p><i><strong>Bioinformatics</strong>,  38(9): 2579-2586, 2022. 
			  </i></p>
			</div>

			
			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://arxiv.org/abs/2102.10757" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/DIG/" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>DIG: A Turnkey Library for Diving into Graph Deep Learning Research.</b>
			  </p>
			  <p style="margin-top: 3px;">Meng Liu*, Youzhi Luo*, Limei Wang*, <strong>Yaochen Xie*</strong>, Hao Yuan*, Shurui Gui*, Haiyang Yu*, Zhao Xu, Jingtun Zhang, Yi Liu, Keqiang Yan, Haoran Liu, Cong Fu, Bora Oztekin, Xuan Zhang, Shuiwang Ji.</p>
			  <p><i>Journal of Machine Learning Research (<strong>JMLR</strong>), 22 (240): 1-9, 2021. 
			  </i></p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://www.nature.com/articles/s42256-020-00283-x" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/GVTNets/" class="fa fa-github" target="_blank"></a>&ensp;
			  	<a href="https://www.youtube.com/watch?v=ZkGvbbBB3Sg" class="fa fa-youtube" target="_blank"></a>&ensp;
			  	<b>Global Voxel Transformer Networks for Augmented Microscopy.</b></p>
			  <p style="margin-top: 3px;">Zhengyang Wang*, <strong>Yaochen Xie*</strong>, and Shuiwang Ji.</p>
			  <p><i><strong>Nature Machine Intelligence</strong>, 3: 161-171, 2021.
			  </i></p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://arxiv.org/abs/2010.11971" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/Noise2Same" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>Noise2Same: Optimizing A Self-Supervised Bound for Image Denoising.</b></p>
			  <p style="margin-top: 3px;"><strong>Yaochen Xie</strong>, Zhengyang Wang, and Shuiwang Ji,</p>
			  <p><i>The 34th Neural Information Processing Systems (<strong>NeurIPS</strong>), 20320-20330, 2020.
			  </i></p>
			</div>


			<div class="paper" style="margin-top: 25px;">
			  <p class="title">
			  	<a href="https://ieeexplore.ieee.org/document/8809830" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<b>Finding the Stars in the Fireworks: Deep Understanding of Motion Sensor Fingerprint.</b></p>
			  <p style="margin-top: 3px;">Xiang-Yang Li, Huiqi Liu, Lan Zhang, Zhenan Wu, <strong>Yaochen Xie</strong>, Ge Chen, Chunxiao Wan, and Zhongwei Liang,</p>
			  <p><i>IEEE/ACM Transactions on Networking, 5 (27): 1945-1958, 2019.
			  </i></p>
			</div>

				</section>

			<h2>Tutorial</h2>
			<section>
				<div class="paper" style="margin-top: 25px;">
					<p class="title">
				<a href="https://dl.acm.org/doi/abs/10.1145/3534678.3542624" class="fa fa-file-pdf-o" target="_blank"></a>&ensp;
			  	<a href="https://github.com/divelab/DIG/tree/dig-stable/tutorials/KDD2022" class="fa fa-github" target="_blank"></a>&ensp;
			  	<b>Frontiers of Graph Neural Networks with DIG.</b></p>
			    <p style="margin-top: 3px;">Shuiwang Ji*, Meng Liu*, Yi Liu, Youzhi Luo, Limei Wang*, <strong>Yaochen Xie*</strong>, Zhao Xu*, Haiyang Yu*</p>
			    <p><i>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD</strong>), 4796–4797, 2022. </i></p>
			</div>

			</section>

		</section>


		<!-- Reviews -->
		<section id="Rev">
			<h2>Services</h2>
			<section>
			<h3 style="margin-bottom: 8px;">Area Chair</h3>
				<p>Language and Molecules @ Annual Meeting of the Association for Computational Linguistics (<strong>ACL</strong>) <span style="float:right">2024</span></p> 
			</section>

			<section>
			<h3 style="margin-bottom: 8px;">Program Committee Member</h3>
				<p>Annual Conference on Neural Information Processing System (<strong>NeurIPS</strong>) <span style="float:right">2021-2023</span></p> 
				<p>International Conference on Machine Learning (<strong>ICML</strong>)<span style="float:right">2022-2024</span></p> 
				<p>ACM SIGKDD Conference on Knowledge Discovery and Data Mining (<strong>KDD</strong>)<span style="float:right">2021-2022</span></p> 
				<p>International Conference on Learning Representation (<strong>ICLR</strong>)<span style="float:right">2022-2023</span></p> 
			</section>

			<h3 style="margin-bottom: 8px;">Journal Reviewer</h3>
				<p>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</p> 
				<p>Transactions on Machine Learning Research (<strong>TMLR</strong>)</p> 
				<p>Nature Communications</p> 
				<p>IEEE Transactions on Image Processing (<strong>TIP</strong>)</p> 
				<p>IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>)</p> 
				<p>Data Mining and Knowledge Discovery (<strong>DAMI</strong>)</p> 
			</section>
		</section>


		<section id="Rev">
			<h2>Miscellaneous</h2>
				<p>+ Meet our new family member <a href="https://www.instagram.com/sesameofraincity/">Sesame</a>, a bernedoodle born on 7/10/2023. Pup training overfits easily!</p> 
				<p>+ I love perfomance driving, and am interested in auto engineering&tuning. My favorite drive is <a href="https://www.raincitysupercars.com/singleday/2020/4/27/the-local">the Local 2.0</a>, WA.</p>
		</section>

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<strong style="background-color: rgba(64,0,64,.6)">Scroll down to denoise &#8595;</strong><br /> 
					<ul class="copyright"><i style="background-color: rgba(64,0,64,.6)">
						Source of Background Image<br /> 
						Noisy data: <a href="https://www.nature.com/articles/s41592-018-0216-7" target="_blank">[Weigert et al. 2018]</a><br />
						Denoised: <a href="https://arxiv.org/abs/2010.11971" target="_blank">[Ours 2020]</a>, <a href="https://www.nature.com/articles/s42256-020-00283-x" target="_blank">[Ours 2021]</a><br /><i>
					</ul>
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/img_comparison.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/skel.min.js"></script>
			<script src="assets/js/util.js"></script>
			<!--[if lte IE 8]><script src="assets/js/ie/respond.min.js"></script><![endif]-->
			<script src="assets/js/main.js"></script>

	</body>
</html>
